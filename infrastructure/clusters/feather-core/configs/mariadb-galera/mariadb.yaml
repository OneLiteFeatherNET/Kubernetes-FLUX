apiVersion: k8s.mariadb.com/v1alpha1
kind: MariaDB
metadata:
  name: mariadb-galera
  namespace: mariadb-galera
spec:
  image: "mariadb:11.4"
  replicas: 3
  galera:
    enabled: true
    recovery:
        enabled: true
        minClusterSize: 1
        clusterMonitorInterval: 10s
        clusterHealthyTimeout: 30s
        clusterBootstrapTimeout: 10m
        podRecoveryTimeout: 10m
        podSyncTimeout: 10m
        forceClusterBootstrapInPod: mariadb-galera-0
  myCnf: |
    [mariadb]
    bind-address=*
    max_connections=100000
    max_user_connections=100000
    default_storage_engine=InnoDB
    binlog_format=row
    innodb_autoinc_lock_mode=2
    innodb_buffer_pool_size=3200MB
    max_allowed_packet=1GB
    # Schedule Pods in different Nodes to achieve real HA.
  affinity:
    antiAffinityEnabled: true
  # When draining Nodes, make sure that you have at least 2 Pods available.
  podDisruptionBudget:
    maxUnavailable: 66%
  bootstrapFrom:
    backupRef:
      name: mariadb-galera-backup
      kind: PhysicalBackup
    targetRecoveryTime: 2025-10-23T06:00:00Z

  # Ensure that the Pods are not preempted by Kubernetes to make room for new scheduled Pods.
  priorityClassName: system-node-critical
  # Configure enough compute resources. This is just an example, take a look at your historic compute metrics to estimate.
  resources:
    requests:
      cpu: 1
      memory: 4Gi
    limits:
      memory: 4Gi

  storage:
    resizeInUseVolumes: true
    waitForVolumeResize: true
    size: 50Gi
    storageClassName: rook-external-rbd
    volumeClaimTemplate:
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: 50Gi
      storageClassName: rook-external-rbd

  rootPasswordSecretKeyRef:
    name: mariadb
    key: password
#  service:
#    type: LoadBalancer
#    metadata:
#      annotations:
#        io.cilium/lb-ipam-ips: 10.200.32.4
  metrics:
    enabled: false

